## TIL
# 딥다이브 - 4. 데이터 증강 기법이 모델의 일반화 성능에 미치는 영향을 설명하시오.

## 데이터 증강(image)

- 기본 연산(flip, rotate, graysclae.. )

![https://av-eks-lekhak.s3.amazonaws.com/media/__sized__/article_images/Screenshot_217_EbrrOOn-thumbnail_webp-600x300.webp](attachment:f5da10e3-63cb-4949-9410-ad9147b8c341:265f54e3-3778-46f9-ae04-7e9ce2aebaca.png)

https://av-eks-lekhak.s3.amazonaws.com/media/__sized__/article_images/Screenshot_217_EbrrOOn-thumbnail_webp-600x300.webp

- 고급 방법(mixup, cutout, gan합성)

![https://av-eks-lekhak.s3.amazonaws.com/media/__sized__/article_images/Screenshot_217_EbrrOOn-thumbnail_webp-600x300.webp](attachment:5339e3aa-f208-46ad-badd-3be4f15c4238:746b33f6-cb39-47d8-9ac5-ebdb1d85139f.png)

https://av-eks-lekhak.s3.amazonaws.com/media/__sized__/article_images/Screenshot_217_EbrrOOn-thumbnail_webp-600x300.webp

![https://www.dentin.kr/data/photos/20231144/art_1698981564056_8e955f.png](attachment:732adc64-d098-42b5-9f58-f33a6d87eed7:image.png)

https://www.dentin.kr/data/photos/20231144/art_1698981564056_8e955f.png

```python
import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt

image = Image.open(image_path)

transformations = {
    "Flip": transforms.RandomHorizontalFlip(p=1),
    "Crop": transforms.RandomResizedCrop(size=(100, 100)),
    "Zoom": transforms.Resize((256, 256)),
    "Color Change": transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),
    "Cutout": transforms.RandomErasing(p=1),
}
```

## 데이터증강(audio)

![https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/295e6c98045616357e1dce5020852c1cdc96ce51/3-Figure2-1.png](attachment:5cf0a87e-9b09-4581-aa36-c2c01138f0ac:image.png)

https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/295e6c98045616357e1dce5020852c1cdc96ce51/3-Figure2-1.png

```python
import torch
from torch_audiomentations import Compose, Gain, PolarityInversion, Shift, TimeStretch

audio_tensor = torch.tensor(y).unsqueeze(0)  # 배치 차원 추가

augmentations = Compose([
    Gain(min_gain_in_db=-6, max_gain_in_db=6, p=0.5),  # 볼륨 변화
    PolarityInversion(p=0.5),  # 위상 반전
    Shift(min_shift=-0.5, max_shift=0.5, p=0.5),  # 시간 이동
    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5)  # 타임 스트레칭
])
```

## 데이터증강(nlp)

![https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTfS6nghNDx0lhXOeqlJe9wdAf2Zf_PhJt__w&s](attachment:062a71c6-adaa-4f3b-b470-d6215a87b0cb:image.png)

https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTfS6nghNDx0lhXOeqlJe9wdAf2Zf_PhJt__w&s

```python
import nlpaug.augmenter.word as naw

sentence = "I am jogging"

# Synonym Augmentation (동의어 치환)
syn_aug = naw.SynonymAug(aug_src='wordnet')

# Random Deletion (랜덤 삭제)
del_aug = naw.RandomWordAug(action="delete")
```

---

# 데이터 증강이 일반화 성능에 미치는 영향

- robustness향상
    - 많은 데이터 학습 → 과적합 방지
    - representation learning 에 기여
    - 노이즈에 강해짐 → new data(테스트) 에 대한 오차를 감소
    
    ![image.png](attachment:d7c708c6-3a06-49b1-9018-11ab08066512:image.png)
    

## 증강 유무에 따른 모델 성능 평가

![https://arxiv.org/pdf/1905.04899](attachment:17a9b72a-3f1f-49e1-933c-09c23a8094a3:스크린샷_2025-02-21_오후_3.31.55.png)

https://arxiv.org/pdf/1905.04899

## 주의사항

> 데이터 증강 무분별하게 하면 성능 저하된다 !!
> 
- 원본 데이터의 분포가 왜곡됨
- 라벨이 왜곡될 수 있음
- 과적합이 여전히 발생 가능 (증강된 데이터가 훈련에 별로 효과적이지 않았을 경우)

# 주제: 딥다이브 - 5. PyTorch에서의 텐서 연산과 벡터 연산의 차이점을 설명하시오.

## 텐서 vs 벡터

|  | **텐서** | **벡터** |
| --- | --- | --- |
| 정의 | 다차원 수치 데이터 구조 | **`크기`**와 **`방향`**을 함께 가진 양.
숫자를 한 줄로 나열한 배열(1차원 배열) |
| 차원 | **다차원 배열(**0차원 ~ n차원)로 
스칼라, 벡터(1차), 행렬(2차), 3차 이상 배열을 모두 포함 | 1차원 배열: 스칼라 or  [1, 2, 3] |
| 연산  | - 모든 차원에서 일반화된 연산 수행 가능
- 고차원 데이터 처리 가능 → 복잡한 연산 수행 가능 | 주로 내적(dot product), 외적(cross product), 덧셈, 뺄셈  |
| 용도  | - 딥러닝 모델 구축 시 사용
- **이미지**(3차 텐서: (3, 256,256))
- **텍스트** 처리 (단어 임베딩 벡터묶음)
- **영상/비디오** (4치 텐서) 등
 | - 기하학적 의미가 중요할 때
- 유사도 계산(코사인 유사도), 임베딩(embedding) 처리, 물리적 힘이나 속도 계산 |

### GPU연산이 요구하는 조건

- 데이터가 **균일한 형태**로 정리되어 있어야 함
- 데이터가 **연속된 메모리 공간**에 저장돼야 함
    - `텐서`는 **연속된 메모리 공간**에 저장되어진 경우가 많음
    - GPU는 메모리에서 연속된 데이터를 **한번에 빠르게 불러와 처리**하는 구조 → 데이터를 읽는 속도가 극대화 됨
    - `벡터, 리스트`는 흩어진 데이터 형태 → 데이터를 읽어 들이는 속도가 저하됨
- 병렬 처리가 가능한 **규칙적인 연산 구조**가 있어야 함

### 🛠 **실제 세부 과정 요약**

| 단계 | 세부 과정 설명 |
| --- | --- |
| 1️⃣ | 텐서를 **메모리에 연속된 형태**로 저장 |
| 2️⃣ | GPU로 텐서 데이터를 **한 번에 전송** |
| 3️⃣ | GPU 코어가  한번의 명령으로 **동시 &** **병렬로 데이터 연산 수행** |
| 4️⃣ | **브로드캐스팅으로** 반복 연산 자동 처리 |
| 5️⃣ | 최적화된 라이브러리(**CUDA**/cuDNN)로 연산 극대화 |
| 6️⃣ | 연산 결과를 다시 텐서 형태의 한번에 CPU메모리로 반환 |

→ 연속적인 메모리 (균일성)

→ 대규모로 한번에 옮기고 보내는게 중요함 (고속성)

→ 병렬로 데이터 연산 수행 ****(병렬성)

→ 브로드캐스팅 반복 연산 처리 (효율성) 

- (1차원) + (0차원) : 1차원 벡터규모를 굳이 확장시키는 것은 제한적이다
- (2차원) + (1차원) : 텐서에서는 가능!

![image.png](attachment:a876321e-cec8-4a27-a9f6-47d28651dbad:image.png)



## 오늘의 훈화
fastapi로 감싸야한다

## 앞으로 공부할 내용
랭체인 필수 공부 !! 
튜토리얼 따라해보기 !

## 느낀점